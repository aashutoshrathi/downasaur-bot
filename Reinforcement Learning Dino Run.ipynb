{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 #opencv\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from random import randint\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#keras imports\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD , Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from collections import deque\n",
    "import random\n",
    "import pickle\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path variables\n",
    "game_url = \"chrome://dino\"\n",
    "chrome_driver_path = \"./chromedriver\"\n",
    "loss_file_path = \"./objects/loss_df.csv\"\n",
    "actions_file_path = \"./objects/actions_df.csv\"\n",
    "q_value_file_path = \"./objects/q_values.csv\"\n",
    "scores_file_path = \"./objects/scores_df.csv\"\n",
    "\n",
    "#scripts\n",
    "#create id for canvas for faster selection from DOM\n",
    "init_script = \"document.getElementsByClassName('runner-canvas')[0].id = 'runner-canvas'\"\n",
    "\n",
    "#get image from canvas\n",
    "getbase64Script = \"canvasRunner = document.getElementById('runner-canvas'); \\\n",
    "return canvasRunner.toDataURL().substring(22)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Game class: Selenium interfacing between the python and browser\n",
    "* __init__():  Launch the broswer window using the attributes in chrome_options\n",
    "* get_crashed() : return true if the agent as crashed on an obstacles. Gets javascript variable from game decribing the state\n",
    "* get_playing(): true if game in progress, false is crashed or paused\n",
    "* restart() : sends a signal to browser-javascript to restart the game\n",
    "* press_up(): sends a single to press up get to the browser\n",
    "* get_score(): gets current game score from javascript variables.\n",
    "* pause(): pause the game\n",
    "* resume(): resume a paused game if not crashed\n",
    "* end(): close the browser and end the game\n",
    "'''\n",
    "class Game:\n",
    "    def __init__(self,custom_config=True):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        chrome_options.add_argument(\"--mute-audio\")\n",
    "        self._driver = webdriver.Chrome(executable_path = chrome_driver_path,chrome_options=chrome_options)\n",
    "        self._driver.set_window_position(x=-10,y=0)\n",
    "        self._driver.get('chrome://dino')\n",
    "        self._driver.execute_script(\"Runner.config.ACCELERATION=0\")\n",
    "        self._driver.execute_script(init_script)\n",
    "    def get_crashed(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.crashed\")\n",
    "    def get_playing(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.playing\")\n",
    "    def restart(self):\n",
    "        self._driver.execute_script(\"Runner.instance_.restart()\")\n",
    "    def press_up(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_UP)\n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array) # the javascript object is of type array with score in the formate[1,0,0] which is 100.\n",
    "        return int(score)\n",
    "    def pause(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.stop()\")\n",
    "    def resume(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.play()\")\n",
    "    def end(self):\n",
    "        self._driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoAgent:\n",
    "    def __init__(self,game): #takes game as input for taking actions\n",
    "        self._game = game; \n",
    "        self.jump(); #to start the game, we need to jump once\n",
    "    def is_running(self):\n",
    "        return self._game.get_playing()\n",
    "    def is_crashed(self):\n",
    "        return self._game.get_crashed()\n",
    "    def jump(self):\n",
    "        self._game.press_up()\n",
    "    def duck(self):\n",
    "        self._game.press_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game_sate:\n",
    "    def __init__(self,agent,game):\n",
    "        self._agent = agent\n",
    "        self._game = game\n",
    "        self._display = show_img() #display the processed image on screen using openCV, implemented using python coroutine \n",
    "        self._display.__next__() # initiliaze the display coroutine \n",
    "    def get_state(self,actions):\n",
    "        actions_df.loc[len(actions_df)] = actions[1] # storing actions in a dataframe\n",
    "        score = self._game.get_score() \n",
    "        reward = 0.1\n",
    "        is_over = False #game over\n",
    "        if actions[1] == 1:\n",
    "            self._agent.jump()\n",
    "        image = grab_screen(self._game._driver) \n",
    "        self._display.send(image) #display the image on screen\n",
    "        if self._agent.is_crashed():\n",
    "            scores_df.loc[len(loss_df)] = score # log the score when game is over\n",
    "            self._game.restart()\n",
    "            reward = -1\n",
    "            is_over = True\n",
    "        return image, reward, is_over #return the Experience tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('objects/'+ name + '.pkl', 'wb') as f: #dump files into objects folder\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_obj(name ):\n",
    "    with open('objects/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def grab_screen(_driver):\n",
    "    image_b64 = _driver.execute_script(getbase64Script)\n",
    "    screen = np.array(Image.open(BytesIO(base64.b64decode(image_b64))))\n",
    "    image = process_img(screen)#processing image as required\n",
    "    return image\n",
    "\n",
    "def process_img(image):\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #RGB to Grey Scale\n",
    "    image = image[:300, :500] #Crop Region of Interest(ROI)\n",
    "    image = cv2.resize(image, (80,80))\n",
    "    return  image\n",
    "\n",
    "def show_img(graphs = False):\n",
    "    \"\"\"\n",
    "    Show images in new window\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        window_title = \"logs\" if graphs else \"game_play\"\n",
    "        cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)        \n",
    "        imS = cv2.resize(screen, (800, 400)) \n",
    "        cv2.imshow(window_title, screen)\n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize log structures from file if exists else create new\n",
    "loss_df = pd.read_csv(loss_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns =['loss'])\n",
    "scores_df = pd.read_csv(scores_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns = ['scores'])\n",
    "actions_df = pd.read_csv(actions_file_path) if os.path.isfile(actions_file_path) else pd.DataFrame(columns = ['actions'])\n",
    "q_values_df =pd.read_csv(actions_file_path) if os.path.isfile(q_value_file_path) else pd.DataFrame(columns = ['qvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game parameters\n",
    "ACTIONS = 2 # possible actions: jump, do nothing\n",
    "GAMMA = 0.99 # decay rate of past observations original 0.99\n",
    "OBSERVATION = 100. # timesteps to observe before training\n",
    "EXPLORE = 100000  # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
    "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
    "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
    "BATCH = 16 # size of minibatch\n",
    "FRAME_PER_ACTION = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "img_rows , img_cols = 80,80\n",
    "img_channels = 4 #We stack 4 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables saved as checkpoints to filesystem to resume training from the same step\n",
    "def init_cache():\n",
    "    \"\"\"initial variable caching, done only once\"\"\"\n",
    "    save_obj(INITIAL_EPSILON,\"epsilon\")\n",
    "    t = 0\n",
    "    save_obj(t,\"time\")\n",
    "    D = deque()\n",
    "    save_obj(D,\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCall only once to init file structure\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Call only once to init file structure\n",
    "'''\n",
    "#init_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmodel():\n",
    "    print(\"Now we build the model\")\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (8, 8), padding='same',strides=(4, 4),input_shape=(img_cols,img_rows,img_channels)))  #80*80*4\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) # \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4),strides=(2, 2),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3),strides=(1, 1),  padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(ACTIONS))\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    \n",
    "    #create model file if not present\n",
    "    if not os.path.isfile(loss_file_path):\n",
    "        model.save_weights('model.h5')\n",
    "    print(\"We finish building the model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "main training module\n",
    "Parameters:\n",
    "* model => Keras Model to be trained\n",
    "* game_state => Game State module with access to game environment and dino\n",
    "* observe => flag to indicate wherther the model is to be trained(weight updates), else just play\n",
    "'''\n",
    "def trainNetwork(model,game_state,observe=False):\n",
    "    last_time = time.time()\n",
    "    # store the previous observations in replay memory\n",
    "    D = load_obj(\"D\") #load from file system\n",
    "    # get the first state by doing nothing\n",
    "    do_nothing = np.zeros(ACTIONS)\n",
    "    do_nothing[0] =1 #0 => do nothing,\n",
    "                     #1=> jump\n",
    "    \n",
    "    x_t, r_0, terminal = game_state.get_state(do_nothing) # get next step after performing the action\n",
    "    \n",
    "\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2) # stack 4 images to create placeholder input\n",
    "    \n",
    "\n",
    "    \n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])  #1*20*40*4\n",
    "    \n",
    "    initial_state = s_t \n",
    "\n",
    "    if observe :\n",
    "        OBSERVE = 999999999    # We keep observe, never train\n",
    "        epsilon = FINAL_EPSILON\n",
    "        print (\"Now we load weight\")\n",
    "        model.load_weights(\"model.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "        print (\"Weight load successfully\")    \n",
    "    else:                       # We go to training mode\n",
    "        OBSERVE = OBSERVATION\n",
    "        epsilon = load_obj(\"epsilon\") \n",
    "        model.load_weights(\"model.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "\n",
    "    t = load_obj(\"time\") # resume from the previous time step stored in file system\n",
    "    while (True): #endless running\n",
    "        \n",
    "        loss = 0\n",
    "        Q_sa = 0\n",
    "        action_index = 0\n",
    "        r_t = 0 #reward at 4\n",
    "        a_t = np.zeros([ACTIONS]) # action at t\n",
    "        \n",
    "        #choose an action epsilon greedy\n",
    "        if t % FRAME_PER_ACTION == 0: #parameter to skip frames for actions\n",
    "            if  random.random() <= epsilon: #randomly explore an action\n",
    "                print(\"----------Random Action----------\")\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                a_t[action_index] = 1\n",
    "            else: # predict the output\n",
    "                q = model.predict(s_t)       #input a stack of 4 images, get the prediction\n",
    "                max_Q = np.argmax(q)         # chosing index with maximum q value\n",
    "                action_index = max_Q \n",
    "                a_t[action_index] = 1        # o=> do nothing, 1=> jump\n",
    "                \n",
    "        #We reduced the epsilon (exploration parameter) gradually\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE \n",
    "\n",
    "        #run the selected action and observed next state and reward\n",
    "        x_t1, r_t, terminal = game_state.get_state(a_t)\n",
    "        print('fps: {0}'.format(1 / (time.time()-last_time))) # helpful for measuring frame rate\n",
    "        last_time = time.time()\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x20x40x1\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3) # append the new image to input stack and remove the first one\n",
    "        \n",
    "        \n",
    "        # store the transition in D\n",
    "        D.append((s_t, action_index, r_t, s_t1, terminal))\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "\n",
    "        #only train if done observing\n",
    "        if t > OBSERVE: \n",
    "            \n",
    "            #sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH)\n",
    "            inputs = np.zeros((BATCH, s_t.shape[1], s_t.shape[2], s_t.shape[3]))   #32, 20, 40, 4\n",
    "            targets = np.zeros((inputs.shape[0], ACTIONS))                         #32, 2\n",
    "\n",
    "            #Now we do the experience replay\n",
    "            for i in range(0, len(minibatch)):\n",
    "                state_t = minibatch[i][0]    # 4D stack of images\n",
    "                action_t = minibatch[i][1]   #This is action index\n",
    "                reward_t = minibatch[i][2]   #reward at state_t due to action_t\n",
    "                state_t1 = minibatch[i][3]   #next state\n",
    "                terminal = minibatch[i][4]   #wheather the agent died or survided due the action\n",
    "                \n",
    "\n",
    "                inputs[i:i + 1] = state_t    \n",
    "\n",
    "                targets[i] = model.predict(state_t)  # predicted q values\n",
    "                Q_sa = model.predict(state_t1)      #predict q values for next step\n",
    "                \n",
    "                if terminal:\n",
    "                    targets[i, action_t] = reward_t # if terminated, only equals reward\n",
    "                else:\n",
    "                    targets[i, action_t] = reward_t + GAMMA * np.max(Q_sa)\n",
    "\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "            loss_df.loc[len(loss_df)] = loss\n",
    "            q_values_df.loc[len(q_values_df)] = np.max(Q_sa)\n",
    "        s_t = initial_state if terminal else s_t1 #reset game to initial frame if terminate\n",
    "        t = t + 1\n",
    "        \n",
    "        # save progress every 1000 iterations\n",
    "        if t % 1000 == 0:\n",
    "            print(\"Now we save model\")\n",
    "            game_state._game.pause() #pause game while saving to filesystem\n",
    "            model.save_weights(\"model.h5\", overwrite=True)\n",
    "            save_obj(D,\"D\") #saving episodes\n",
    "            save_obj(t,\"time\") #caching time steps\n",
    "            save_obj(epsilon,\"epsilon\") #cache epsilon to avoid repeated randomness in actions\n",
    "            loss_df.to_csv(\"./objects/loss_df.csv\",index=False)\n",
    "            scores_df.to_csv(\"./objects/scores_df.csv\",index=False)\n",
    "            actions_df.to_csv(\"./objects/actions_df.csv\",index=False)\n",
    "            q_values_df.to_csv(q_value_file_path,index=False)\n",
    "            with open(\"model.json\", \"w\") as outfile:\n",
    "                json.dump(model.to_json(), outfile)\n",
    "            clear_output()\n",
    "            game_state._game.resume()\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "\n",
    "        print(\"TIMESTEP\", t, \"/ STATE\", state,             \"/ EPSILON\", epsilon, \"/ ACTION\", action_index, \"/ REWARD\", r_t,             \"/ Q_MAX \" , np.max(Q_sa), \"/ Loss \", loss)\n",
    "\n",
    "    print(\"Episode finished!\")\n",
    "    print(\"************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "def playGame(observe=False):\n",
    "    game = Game()\n",
    "    dino = DinoAgent(game)\n",
    "    game_state = Game_sate(dino,game)    \n",
    "    model = buildmodel()\n",
    "    try:\n",
    "        trainNetwork(model,game_state,observe=observe)\n",
    "    except StopIteration:\n",
    "        game.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 103000 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0594629 / Loss  0.027285892516374588\n",
      "fps: 0.025000151396714562\n",
      "TIMESTEP 103001 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  1.7132034 / Loss  0.0268790815025568\n",
      "fps: 6.250154975919126\n",
      "TIMESTEP 103002 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.13694799 / Loss  0.04480805993080139\n",
      "fps: 6.493454378816215\n",
      "TIMESTEP 103003 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.86492 / Loss  0.10390789061784744\n",
      "fps: 6.944188926526733\n",
      "TIMESTEP 103004 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.03296744 / Loss  0.06285853683948517\n",
      "fps: 4.504651999505963\n",
      "TIMESTEP 103005 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.28313214 / Loss  0.01705542579293251\n",
      "fps: 6.71141257474586\n",
      "TIMESTEP 103006 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.20172007 / Loss  0.050351906567811966\n",
      "fps: 6.802772812938929\n",
      "TIMESTEP 103007 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.19570631 / Loss  0.07566051185131073\n",
      "fps: 5.5865283055558885\n",
      "TIMESTEP 103008 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9467228 / Loss  0.03392741084098816\n",
      "fps: 7.142863954823042\n",
      "TIMESTEP 103009 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.041835926 / Loss  0.04408251494169235\n",
      "fps: 6.896382538980482\n",
      "TIMESTEP 103010 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.664118 / Loss  0.04778198525309563\n",
      "fps: 6.802982455286689\n",
      "TIMESTEP 103011 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.0991439 / Loss  0.04348945617675781\n",
      "fps: 6.2499314554102545\n",
      "TIMESTEP 103012 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.71545327 / Loss  0.03492145240306854\n",
      "fps: 6.7567240157226625\n",
      "TIMESTEP 103013 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.048220456 / Loss  0.08901049196720123\n",
      "fps: 5.987962127528353\n",
      "TIMESTEP 103014 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.1211903 / Loss  0.09071823209524155\n",
      "fps: 6.369588558047287\n",
      "TIMESTEP 103015 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.12492666 / Loss  0.06698190420866013\n",
      "fps: 6.289377360782262\n",
      "TIMESTEP 103016 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.529529 / Loss  0.03944025933742523\n",
      "fps: 6.535708497986762\n",
      "TIMESTEP 103017 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.68897015 / Loss  0.03709334880113602\n",
      "fps: 5.464570806923373\n",
      "TIMESTEP 103018 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.30400157 / Loss  0.03521530330181122\n",
      "fps: 6.134480771537136\n",
      "TIMESTEP 103019 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0259491 / Loss  0.05101456493139267\n",
      "fps: 6.289009575275218\n",
      "TIMESTEP 103020 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.83693135 / Loss  0.10917593538761139\n",
      "fps: 6.25073247790644\n",
      "TIMESTEP 103021 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.15379004 / Loss  0.034892622381448746\n",
      "fps: 6.1349473579513045\n",
      "TIMESTEP 103022 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.513319 / Loss  0.009556970559060574\n",
      "fps: 6.536513146104013\n",
      "TIMESTEP 103023 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.5175043 / Loss  0.013662807643413544\n",
      "fps: 6.536105704575098\n",
      "TIMESTEP 103024 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.17014429 / Loss  0.026839379221200943\n",
      "fps: 6.409741367190127\n",
      "TIMESTEP 103025 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.40565217 / Loss  0.039967283606529236\n",
      "fps: 6.289471671687583\n",
      "TIMESTEP 103026 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7735684 / Loss  0.026907904073596\n",
      "fps: 5.987893739007286\n",
      "TIMESTEP 103027 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.29626808 / Loss  0.07902421057224274\n",
      "fps: 5.848385257113695\n",
      "TIMESTEP 103028 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.21684517 / Loss  0.018195657059550285\n",
      "fps: 6.451643865537429\n",
      "TIMESTEP 103029 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.7852545 / Loss  0.011257442645728588\n",
      "fps: 6.369395103180063\n",
      "TIMESTEP 103030 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.05188086 / Loss  0.07574379444122314\n",
      "fps: 6.060730067076466\n",
      "TIMESTEP 103031 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6788988 / Loss  0.03551013395190239\n",
      "fps: 4.608223885877268\n",
      "TIMESTEP 103032 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.43637648 / Loss  0.04401715472340584\n",
      "fps: 5.813875220049069\n",
      "TIMESTEP 103033 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7494032 / Loss  9.606000900268555\n",
      "fps: 6.172650986463537\n",
      "TIMESTEP 103034 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.62219095 / Loss  0.02366921864449978\n",
      "fps: 4.1494730927064\n",
      "TIMESTEP 103035 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.23018771 / Loss  0.015927521511912346\n",
      "fps: 7.142876119080179\n",
      "TIMESTEP 103036 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.26519704 / Loss  0.03198348358273506\n",
      "fps: 5.5865580692208825\n",
      "TIMESTEP 103037 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.149791 / Loss  0.01617489941418171\n",
      "fps: 6.756843748439385\n",
      "TIMESTEP 103038 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.25383377 / Loss  0.0599023811519146\n",
      "fps: 7.352881159826797\n",
      "TIMESTEP 103039 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.35666308 / Loss  0.06956644356250763\n",
      "fps: 4.032251831157607\n",
      "TIMESTEP 103040 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.3431024 / Loss  0.029847871512174606\n",
      "fps: 5.263110079367569\n",
      "TIMESTEP 103041 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.5999392 / Loss  0.36283865571022034\n",
      "fps: 5.525007607202276\n",
      "TIMESTEP 103042 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.273876 / Loss  0.014933574944734573\n",
      "fps: 6.451495010990127\n",
      "TIMESTEP 103043 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.04285699 / Loss  0.02777085267007351\n",
      "fps: 6.250015273727549\n",
      "TIMESTEP 103044 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  2.4035323 / Loss  0.02555815689265728\n",
      "fps: 6.756626055746985\n",
      "TIMESTEP 103045 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.73497546 / Loss  0.025915157049894333\n",
      "fps: 6.4935549094467095\n",
      "TIMESTEP 103046 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.3071316 / Loss  0.04222584143280983\n",
      "fps: 6.756898173804338\n",
      "TIMESTEP 103047 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.22565399 / Loss  0.02339250035583973\n",
      "fps: 6.209947336238206\n",
      "TIMESTEP 103048 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.5400769 / Loss  0.02689216285943985\n",
      "fps: 6.53583071025649\n",
      "TIMESTEP 103049 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.31975645 / Loss  0.0223107747733593\n",
      "fps: 6.62253646552078\n",
      "TIMESTEP 103050 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.29265082 / Loss  0.012885130010545254\n",
      "fps: 6.802706612776614\n",
      "TIMESTEP 103051 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.29104263 / Loss  0.025032831355929375\n",
      "fps: 6.249372724076072\n",
      "TIMESTEP 103052 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.21778005 / Loss  0.02070004679262638\n",
      "fps: 6.711380357594319\n",
      "TIMESTEP 103053 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.09988294 / Loss  0.07555340230464935\n",
      "fps: 6.250667270724885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 103054 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.5694027 / Loss  0.01608894020318985\n",
      "fps: 5.714365123373111\n",
      "TIMESTEP 103055 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.38264084 / Loss  0.03883735090494156\n",
      "fps: 5.813826867525324\n",
      "TIMESTEP 103056 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.07011871 / Loss  0.04351247102022171\n",
      "fps: 5.917096121154836\n",
      "TIMESTEP 103057 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.45361277 / Loss  6.778870105743408\n",
      "fps: 4.132274428552991\n",
      "TIMESTEP 103058 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.27328146 / Loss  0.014627338387072086\n",
      "fps: 4.807765227498332\n",
      "TIMESTEP 103059 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.48890436 / Loss  0.02238290011882782\n",
      "fps: 5.714248346067073\n",
      "TIMESTEP 103060 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.31115666 / Loss  0.07897739112377167\n",
      "fps: 5.102056853278448\n",
      "TIMESTEP 103061 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.24177426 / Loss  0.014779905788600445\n",
      "fps: 4.999820000452979\n",
      "TIMESTEP 103062 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  2.738236 / Loss  0.024723097681999207\n",
      "fps: 4.016159225245773\n",
      "TIMESTEP 103063 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.09738933 / Loss  0.022250935435295105\n",
      "fps: 1.5174585533018432\n",
      "TIMESTEP 103064 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.34358037 / Loss  0.02491729147732258\n",
      "fps: 3.0302862163036943\n",
      "TIMESTEP 103065 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.5067552 / Loss  0.03857000172138214\n",
      "fps: 4.587182412044363\n",
      "TIMESTEP 103066 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.10345473 / Loss  0.0206860713660717\n",
      "fps: 3.6363812912466145\n",
      "TIMESTEP 103067 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.004104607 / Loss  0.024719296023249626\n",
      "fps: 4.672803779861608\n",
      "TIMESTEP 103068 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.082646325 / Loss  11.836492538452148\n",
      "fps: 4.000095369705432\n",
      "TIMESTEP 103069 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.31316864 / Loss  6.311743259429932\n",
      "fps: 5.952373113231646\n",
      "TIMESTEP 103070 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.41187814 / Loss  0.07103971391916275\n",
      "fps: 4.065024040441829\n",
      "TIMESTEP 103071 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.51183677 / Loss  0.08397302031517029\n",
      "fps: 4.739214097744573\n",
      "TIMESTEP 103072 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.058788724 / Loss  0.03792434185743332\n",
      "fps: 5.40565787269142\n",
      "TIMESTEP 103073 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.50116897 / Loss  0.45712220668792725\n",
      "fps: 5.917046036473109\n",
      "TIMESTEP 103074 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.011813521 / Loss  0.05148710310459137\n",
      "fps: 6.535779787921994\n",
      "TIMESTEP 103075 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.21393627 / Loss  0.02623535692691803\n",
      "fps: 5.3189813253119\n",
      "TIMESTEP 103076 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.23565874 / Loss  0.026209402829408646\n",
      "fps: 5.8825648031012365\n",
      "TIMESTEP 103077 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.2207107 / Loss  0.020067624747753143\n",
      "fps: 5.780319672334479\n",
      "TIMESTEP 103078 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.10400604 / Loss  0.021589141339063644\n",
      "fps: 4.950573393953987\n",
      "TIMESTEP 103079 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.034211695 / Loss  0.08443722873926163\n",
      "fps: 5.987962127528353\n",
      "TIMESTEP 103080 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.5636164 / Loss  0.08238319307565689\n",
      "fps: 6.756364843031413\n",
      "TIMESTEP 103081 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5177247 / Loss  0.07783526182174683\n",
      "fps: 6.173305113433987\n",
      "TIMESTEP 103082 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.13065141 / Loss  0.01744929701089859\n",
      "fps: 6.4931528056003645\n",
      "TIMESTEP 103083 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.08247798 / Loss  0.06779604405164719\n",
      "fps: 6.211142817794508\n",
      "TIMESTEP 103084 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.17827621 / Loss  0.040237776935100555\n",
      "fps: 6.250052527034659\n",
      "TIMESTEP 103085 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.0068007857 / Loss  0.20263232290744781\n",
      "fps: 5.347633454838467\n",
      "TIMESTEP 103086 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.5892116 / Loss  0.031060688197612762\n",
      "fps: 7.19427244316525\n",
      "TIMESTEP 103087 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.31288394 / Loss  7.590342998504639\n",
      "fps: 6.943867026472195\n",
      "TIMESTEP 103088 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  4.055139 / Loss  0.37830352783203125\n",
      "fps: 6.756549866618555\n",
      "TIMESTEP 103089 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.6150665 / Loss  7.666392803192139\n",
      "fps: 7.194210743879618\n",
      "TIMESTEP 103090 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.13234057 / Loss  7.726180553436279\n",
      "fps: 6.944786820101002\n",
      "TIMESTEP 103091 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.0075233206 / Loss  0.12249191105365753\n",
      "fps: 7.407224787856847\n",
      "TIMESTEP 103092 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  17.092514 / Loss  0.012641515582799911\n",
      "fps: 6.173023458438135\n",
      "TIMESTEP 103093 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5395662 / Loss  0.054916929453611374\n",
      "fps: 7.092148981824515\n",
      "TIMESTEP 103094 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.804564 / Loss  0.1808546930551529\n",
      "fps: 5.95242379775147\n",
      "TIMESTEP 103095 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.524296 / Loss  0.16033145785331726\n",
      "fps: 6.62253646552078\n",
      "TIMESTEP 103096 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.8872948 / Loss  0.07700412720441818\n",
      "fps: 6.849431215073535\n",
      "TIMESTEP 103097 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.30054104 / Loss  0.08513599634170532\n",
      "fps: 7.352958501044837\n",
      "TIMESTEP 103098 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5021492 / Loss  0.045227378606796265\n",
      "fps: 6.802805913503256\n",
      "TIMESTEP 103099 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.06349269 / Loss  6.314206600189209\n",
      "fps: 6.993024155362598\n",
      "TIMESTEP 103100 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.8614279 / Loss  0.057795923203229904\n",
      "fps: 5.881723385518042\n",
      "TIMESTEP 103101 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.443991 / Loss  0.026125816628336906\n",
      "fps: 6.711960313650184\n",
      "TIMESTEP 103102 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5706049 / Loss  0.10139919817447662\n",
      "fps: 4.629714786528661\n",
      "TIMESTEP 103103 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.60902816 / Loss  0.023283420130610466\n",
      "fps: 7.194334143509188\n",
      "TIMESTEP 103104 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.33617076 / Loss  0.08052905648946762\n",
      "fps: 6.756647824384995\n",
      "TIMESTEP 103105 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.43297753 / Loss  0.05530637130141258\n",
      "fps: 7.352700703311807\n",
      "TIMESTEP 103106 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5257876 / Loss  0.069697804749012\n",
      "fps: 7.299532369530751\n",
      "TIMESTEP 103107 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.301978 / Loss  0.07558843493461609\n",
      "fps: 7.193532121578003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 103108 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.3339603 / Loss  0.05409689247608185\n",
      "fps: 7.298490814904269\n",
      "TIMESTEP 103109 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  1.0974813 / Loss  0.4482983350753784\n",
      "fps: 7.141380226246501\n",
      "TIMESTEP 103110 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.78872883 / Loss  0.0475812591612339\n",
      "fps: 6.850538742590962\n",
      "TIMESTEP 103111 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.6592564 / Loss  0.07740753144025803\n",
      "fps: 6.992266387040739\n",
      "TIMESTEP 103112 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.664974 / Loss  0.08539074659347534\n",
      "fps: 6.89694954607417\n",
      "TIMESTEP 103113 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.008366287 / Loss  0.037777408957481384\n",
      "fps: 6.944786820101002\n",
      "TIMESTEP 103114 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.3345614 / Loss  0.07520577311515808\n",
      "fps: 7.194321803355734\n",
      "TIMESTEP 103115 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.43171504 / Loss  0.050527557730674744\n",
      "fps: 5.235635189806106\n",
      "TIMESTEP 103116 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.015048929 / Loss  0.049091584980487823\n",
      "fps: 4.9747650382628255\n",
      "TIMESTEP 103117 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.4061972 / Loss  0.031143605709075928\n",
      "fps: 5.263466734264392\n",
      "TIMESTEP 103118 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.47470358 / Loss  0.14316615462303162\n",
      "fps: 6.097719263558228\n",
      "TIMESTEP 103119 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.039373286 / Loss  0.21323300898075104\n",
      "fps: 5.555605005775079\n",
      "TIMESTEP 103120 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.55939555 / Loss  0.013186469674110413\n",
      "fps: 5.987945030251636\n",
      "TIMESTEP 103121 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.48588106 / Loss  0.09469780325889587\n",
      "fps: 5.848026468976614\n",
      "TIMESTEP 103122 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.33653027 / Loss  0.10307657718658447\n",
      "fps: 5.882292553422744\n",
      "TIMESTEP 103123 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.38433075 / Loss  0.08938717842102051\n",
      "fps: 5.555516702429204\n",
      "TIMESTEP 103124 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.30591205 / Loss  0.09457391500473022\n",
      "fps: 6.0607213093908365\n",
      "TIMESTEP 103125 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.12678489 / Loss  0.013690455816686153\n",
      "fps: 6.211142817794508\n",
      "TIMESTEP 103126 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.53306025 / Loss  0.20241525769233704\n",
      "fps: 5.813851043686663\n",
      "TIMESTEP 103127 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.2856229 / Loss  0.1787811517715454\n",
      "fps: 5.952474483134459\n",
      "TIMESTEP 103128 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.12767343 / Loss  0.054359320551157\n",
      "fps: 5.464606404877921\n",
      "TIMESTEP 103129 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.42886817 / Loss  0.055068280547857285\n",
      "fps: 5.882160562649445\n",
      "TIMESTEP 103130 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.6007423 / Loss  0.040770284831523895\n",
      "fps: 4.878135696316774\n",
      "TIMESTEP 103131 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.29039913 / Loss  0.12436516582965851\n",
      "fps: 5.987902287486991\n",
      "TIMESTEP 103132 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.6980821 / Loss  0.12066960334777832\n",
      "fps: 7.0421017991820065\n",
      "TIMESTEP 103133 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.67048323 / Loss  0.07399128377437592\n",
      "fps: 5.882424550119701\n",
      "TIMESTEP 103134 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.6387733 / Loss  0.02702154964208603\n",
      "fps: 6.134956331462556\n",
      "TIMESTEP 103135 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.014127396 / Loss  0.033752694725990295\n",
      "fps: 5.5857396839771205\n",
      "TIMESTEP 103136 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.49816966 / Loss  0.04099154472351074\n",
      "fps: 5.917146206684452\n",
      "TIMESTEP 103137 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.35355884 / Loss  0.1315268874168396\n",
      "fps: 4.716983508623559\n",
      "TIMESTEP 103138 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.22647834 / Loss  6.235570430755615\n",
      "fps: 3.322268357093408\n",
      "TIMESTEP 103139 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  14.570514 / Loss  0.12471767514944077\n",
      "fps: 5.405421009763591\n",
      "TIMESTEP 103140 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  17.146822 / Loss  0.046420469880104065\n",
      "fps: 6.097089919016629\n",
      "TIMESTEP 103141 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.06510549 / Loss  0.07937251776456833\n",
      "fps: 6.097497648548496\n",
      "TIMESTEP 103142 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.31290144 / Loss  0.10414376854896545\n",
      "fps: 5.917271424218142\n",
      "TIMESTEP 103143 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.1215215 / Loss  0.024323664605617523\n",
      "fps: 6.097444463343117\n",
      "TIMESTEP 103144 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  8.376559 / Loss  0.16872021555900574\n",
      "fps: 5.681783576852948\n",
      "TIMESTEP 103145 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.025281437 / Loss  0.07625997811555862\n",
      "fps: 5.988184401010808\n",
      "TIMESTEP 103146 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.045597225 / Loss  0.2229924350976944\n",
      "fps: 6.060554918172544\n",
      "TIMESTEP 103147 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.2568194 / Loss  8.326634407043457\n",
      "fps: 5.780343570626297\n",
      "TIMESTEP 103148 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.013219 / Loss  0.04729970544576645\n",
      "fps: 6.493122649819417\n",
      "TIMESTEP 103149 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8842984 / Loss  0.07195991277694702\n",
      "fps: 6.329553583016175\n",
      "TIMESTEP 103150 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.4773925 / Loss  0.07055644690990448\n",
      "fps: 7.193791216801448\n",
      "TIMESTEP 103151 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.4192124 / Loss  0.0777592882514\n",
      "fps: 6.757137655826602\n",
      "TIMESTEP 103152 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.029820591 / Loss  0.20174752175807953\n",
      "fps: 7.462337851806648\n",
      "TIMESTEP 103153 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.3706288 / Loss  0.21503454446792603\n",
      "fps: 7.092005079360785\n",
      "TIMESTEP 103154 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.46223766 / Loss  0.2464028149843216\n",
      "fps: 7.462417512814537\n",
      "TIMESTEP 103155 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.2225938 / Loss  0.06535347551107407\n",
      "fps: 7.194260103223461\n",
      "TIMESTEP 103156 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.34220725 / Loss  0.06671236455440521\n",
      "fps: 7.042432871707389\n",
      "TIMESTEP 103157 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6593174 / Loss  0.027693914249539375\n",
      "fps: 7.3531002975037385\n",
      "TIMESTEP 103158 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.3882333 / Loss  0.0531105101108551\n",
      "fps: 6.8964959329407955\n",
      "TIMESTEP 103159 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  4.166796 / Loss  0.5148755311965942\n",
      "fps: 6.622494639547038\n",
      "TIMESTEP 103160 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  3.5414543 / Loss  0.2757090926170349\n",
      "fps: 6.896280487604366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 103161 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.038287856 / Loss  0.030254561454057693\n",
      "fps: 6.8029383189818065\n",
      "TIMESTEP 103162 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.4532395 / Loss  0.09497331082820892\n",
      "fps: 7.194346483704974\n",
      "TIMESTEP 103163 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.15370934 / Loss  0.028733309358358383\n",
      "fps: 6.410152799386235\n",
      "TIMESTEP 103164 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.12191711 / Loss  0.10549937933683395\n",
      "fps: 6.621741862352269\n",
      "TIMESTEP 103165 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.20789605 / Loss  0.09544931352138519\n",
      "fps: 6.897459932181538\n",
      "TIMESTEP 103166 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.653175 / Loss  0.019402269273996353\n",
      "fps: 5.882325552041625\n",
      "TIMESTEP 103167 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.4321489 / Loss  0.02443457394838333\n",
      "fps: 5.952398455383664\n",
      "TIMESTEP 103168 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.16786978 / Loss  0.057376425713300705\n",
      "fps: 5.076178304480849\n",
      "TIMESTEP 103169 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.25570244 / Loss  0.03733597695827484\n",
      "fps: 5.52488388573777\n",
      "TIMESTEP 103170 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.090767935 / Loss  0.12119472026824951\n",
      "fps: 6.578939195495149\n",
      "TIMESTEP 103171 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.1126091 / Loss  0.022164858877658844\n",
      "fps: 6.211455558138949\n",
      "TIMESTEP 103172 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.15626594 / Loss  0.03540091589093208\n",
      "fps: 4.366892318199897\n",
      "TIMESTEP 103173 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.45958874 / Loss  0.16985300183296204\n",
      "fps: 6.578206604078381\n",
      "TIMESTEP 103174 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.121570714 / Loss  0.328398734331131\n",
      "fps: 6.944625838626143\n",
      "TIMESTEP 103175 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.38613337 / Loss  0.1912970244884491\n",
      "fps: 6.944959308534859\n",
      "TIMESTEP 103176 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.77848446 / Loss  14.818445205688477\n",
      "fps: 6.944660334028191\n",
      "TIMESTEP 103177 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0362967 / Loss  0.07051604986190796\n",
      "fps: 7.092184958352919\n",
      "TIMESTEP 103178 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.2608184 / Loss  0.04464609548449516\n",
      "fps: 7.518654555949327\n",
      "TIMESTEP 103179 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.2606722 / Loss  0.18366369605064392\n",
      "fps: 6.802728679354225\n",
      "TIMESTEP 103180 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.14080916 / Loss  0.02517101913690567\n",
      "fps: 6.849308178565538\n",
      "TIMESTEP 103181 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.485456 / Loss  8.344009399414062\n",
      "fps: 6.249903516470744\n",
      "TIMESTEP 103182 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.017826177 / Loss  6.418910026550293\n",
      "fps: 7.1429004477187465\n",
      "TIMESTEP 103183 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.019370966 / Loss  8.40086841583252\n",
      "fps: 6.024091747994628\n",
      "TIMESTEP 103184 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.12580636 / Loss  0.26277345418930054\n",
      "fps: 6.944809818063807\n",
      "TIMESTEP 103185 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.087947436 / Loss  0.02033550664782524\n",
      "fps: 6.535637209606722\n",
      "TIMESTEP 103186 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.25669265 / Loss  0.46058782935142517\n",
      "fps: 6.802949353004337\n",
      "TIMESTEP 103187 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.693604 / Loss  0.1375025361776352\n",
      "fps: 6.7114877493023375\n",
      "TIMESTEP 103188 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.38257945 / Loss  0.22148311138153076\n",
      "fps: 6.534669878196599\n",
      "TIMESTEP 103189 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.70250946 / Loss  0.04631693661212921\n",
      "fps: 6.898061150481628\n",
      "TIMESTEP 103190 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.3400954 / Loss  0.018942339345812798\n",
      "fps: 6.410152799386235\n",
      "TIMESTEP 103191 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  17.961199 / Loss  0.053080394864082336\n",
      "fps: 6.288783267111477\n",
      "TIMESTEP 103192 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.56808627 / Loss  0.09064861387014389\n",
      "fps: 6.756821978538899\n",
      "TIMESTEP 103193 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.06537786 / Loss  0.07520704716444016\n",
      "fps: 6.84921870024511\n",
      "TIMESTEP 103194 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.00031207502 / Loss  0.07360905408859253\n",
      "fps: 6.944510856427595\n",
      "TIMESTEP 103195 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.82201105 / Loss  0.18506546318531036\n",
      "fps: 7.042326452143691\n",
      "TIMESTEP 103196 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.04735122 / Loss  0.04015960544347763\n",
      "fps: 7.092172966136229\n",
      "TIMESTEP 103197 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  18.400951 / Loss  0.04039975255727768\n",
      "fps: 6.09780791407279\n",
      "TIMESTEP 103198 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.79985476 / Loss  0.1416742205619812\n",
      "fps: 7.2989226429442775\n",
      "TIMESTEP 103199 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.77649146 / Loss  0.2012188583612442\n",
      "fps: 6.849621371098783\n",
      "TIMESTEP 103200 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.1026873 / Loss  0.03096337988972664\n",
      "fps: 6.944407375704283\n",
      "TIMESTEP 103201 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.40071115 / Loss  0.07325587421655655\n",
      "fps: 7.042622069984552\n",
      "TIMESTEP 103202 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.34610063 / Loss  0.13106194138526917\n",
      "fps: 6.944395878036504\n",
      "TIMESTEP 103203 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.12211176 / Loss  0.11039332300424576\n",
      "fps: 6.756865518480153\n",
      "TIMESTEP 103204 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.6316319 / Loss  5.966719150543213\n",
      "fps: 6.451554551984779\n",
      "TIMESTEP 103205 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5822239 / Loss  0.058825552463531494\n",
      "fps: 6.756941714727583\n",
      "TIMESTEP 103206 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.79896665 / Loss  0.4505084753036499\n",
      "fps: 4.716903938003187\n",
      "TIMESTEP 103207 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.5193318 / Loss  0.036992356181144714\n",
      "fps: 5.916987605416035\n",
      "TIMESTEP 103208 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.37677923 / Loss  0.14388133585453033\n",
      "fps: 6.211611940121676\n",
      "TIMESTEP 103209 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.64823383 / Loss  0.18709765374660492\n",
      "fps: 7.092208942907967\n",
      "TIMESTEP 103210 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.447042 / Loss  0.14647142589092255\n",
      "fps: 6.172968947536511\n",
      "TIMESTEP 103211 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.2383312 / Loss  8.623488426208496\n",
      "fps: 7.042078152335605\n",
      "TIMESTEP 103212 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.33591115 / Loss  0.017978550866246223\n",
      "fps: 6.994236926360726\n",
      "TIMESTEP 103213 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  5.5102663 / Loss  0.7801949381828308\n",
      "fps: 7.407381766869822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 103214 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.25389028 / Loss  0.09016649425029755\n",
      "fps: 7.042089975738954\n",
      "TIMESTEP 103215 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.17462492 / Loss  6.111541271209717\n",
      "fps: 6.944591343566784\n",
      "TIMESTEP 103216 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.8920894 / Loss  0.1666712462902069\n",
      "fps: 7.042042682363766\n",
      "TIMESTEP 103217 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.45996165 / Loss  8.535443305969238\n",
      "fps: 6.993129090075445\n",
      "TIMESTEP 103218 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.19053753 / Loss  0.04762118309736252\n",
      "fps: 7.194186064461684\n",
      "TIMESTEP 103219 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.18668422 / Loss  0.14252789318561554\n",
      "fps: 6.848760160543942\n",
      "TIMESTEP 103220 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.6554365 / Loss  0.23250949382781982\n",
      "fps: 7.0923408608605225\n",
      "TIMESTEP 103221 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6369885 / Loss  0.2421724796295166\n",
      "fps: 6.711337401873406\n",
      "TIMESTEP 103222 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.3640824 / Loss  0.18433897197246552\n",
      "fps: 6.578856641826512\n",
      "TIMESTEP 103223 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.031846076 / Loss  0.19279694557189941\n",
      "fps: 6.02410905231288\n",
      "TIMESTEP 103224 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.5572509 / Loss  0.06216638907790184\n",
      "fps: 7.299811861595574\n",
      "TIMESTEP 103225 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.49034858 / Loss  0.3961990773677826\n",
      "fps: 6.802596282035895\n",
      "TIMESTEP 103226 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5772206 / Loss  0.14720503985881805\n",
      "fps: 6.849498327759197\n",
      "TIMESTEP 103227 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.66486317 / Loss  0.259598046541214\n",
      "fps: 6.849173961961589\n",
      "TIMESTEP 103228 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.586558 / Loss  0.11194466054439545\n",
      "fps: 7.142961270040225\n",
      "TIMESTEP 103229 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.19027929 / Loss  0.013071997091174126\n",
      "fps: 6.9930358146196205\n",
      "TIMESTEP 103230 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6084591 / Loss  0.2142390012741089\n",
      "fps: 6.2499500815087\n",
      "TIMESTEP 103231 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.045707926 / Loss  0.02673659846186638\n",
      "fps: 6.493293536281783\n",
      "TIMESTEP 103232 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.017588764 / Loss  0.4066678285598755\n",
      "fps: 6.45188204710117\n",
      "TIMESTEP 103233 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.0761633 / Loss  0.054785750806331635\n",
      "fps: 6.535922372458242\n",
      "TIMESTEP 103234 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0884897 / Loss  0.0674837976694107\n",
      "fps: 6.756473679208354\n",
      "TIMESTEP 103235 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.08526539 / Loss  0.2765202224254608\n",
      "fps: 4.67301723119843\n",
      "TIMESTEP 103236 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.68069303 / Loss  0.2316628396511078\n",
      "fps: 5.649929145271053\n",
      "TIMESTEP 103237 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5894458 / Loss  0.15030014514923096\n",
      "fps: 6.847586131459553\n",
      "TIMESTEP 103238 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.04044725 / Loss  0.06863564252853394\n",
      "fps: 6.2125964075013815\n",
      "TIMESTEP 103239 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.4452478 / Loss  0.21970893442630768\n",
      "fps: 5.263103475103083\n",
      "TIMESTEP 103240 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.49134284 / Loss  0.2403286248445511\n",
      "fps: 6.097143098037106\n",
      "TIMESTEP 103241 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.63880473 / Loss  0.12662899494171143\n",
      "fps: 4.425122832042151\n",
      "TIMESTEP 103242 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.24134985 / Loss  0.26394569873809814\n",
      "fps: 6.756789323951195\n",
      "TIMESTEP 103243 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.08102527 / Loss  7.970470905303955\n",
      "fps: 7.406596938334043\n",
      "TIMESTEP 103244 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.04840272 / Loss  0.14594674110412598\n",
      "fps: 6.623007044132811\n",
      "TIMESTEP 103245 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  17.210209 / Loss  0.02668137475848198\n",
      "fps: 6.622452814101613\n",
      "TIMESTEP 103246 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.5156322 / Loss  0.23145516216754913\n",
      "fps: 5.68188363684639\n",
      "TIMESTEP 103247 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.36746845 / Loss  0.09027520567178726\n",
      "fps: 6.023494809887351\n",
      "TIMESTEP 103248 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.20319724 / Loss  0.2192353755235672\n",
      "fps: 5.464492493055881\n",
      "TIMESTEP 103249 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.14573078 / Loss  0.051433268934488297\n",
      "fps: 5.74762965145359\n",
      "TIMESTEP 103250 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.28061277 / Loss  8.14168930053711\n",
      "fps: 6.5357594192103745\n",
      "TIMESTEP 103251 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.19160342 / Loss  0.031095271930098534\n",
      "fps: 5.347728909940521\n",
      "TIMESTEP 103252 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5719405 / Loss  0.1568232625722885\n",
      "fps: 6.1342385335055205\n",
      "TIMESTEP 103253 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.42225617 / Loss  0.09918388724327087\n",
      "fps: 5.291535670490157\n",
      "TIMESTEP 103254 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.99537235 / Loss  0.1734929084777832\n",
      "fps: 5.882333801754194\n",
      "TIMESTEP 103255 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.3232232 / Loss  3.5412867069244385\n",
      "fps: 6.060563675377312\n",
      "TIMESTEP 103256 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.32767257 / Loss  0.018092108890414238\n",
      "fps: 6.134767893238788\n",
      "TIMESTEP 103257 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.35942 / Loss  0.02752165123820305\n",
      "fps: 6.329161982510808\n",
      "TIMESTEP 103258 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.21534303 / Loss  0.04312711954116821\n",
      "fps: 6.0610891539801015\n",
      "TIMESTEP 103259 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.25419283 / Loss  0.09274979680776596\n",
      "fps: 5.780359502930626\n",
      "TIMESTEP 103260 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.13849844 / Loss  0.11676020920276642\n",
      "fps: 6.097276049646895\n",
      "TIMESTEP 103261 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.976564 / Loss  0.05657525733113289\n",
      "fps: 6.097923163595391\n",
      "TIMESTEP 103262 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.3484496 / Loss  0.2053578644990921\n",
      "fps: 6.211124422284385\n",
      "TIMESTEP 103263 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.45356083 / Loss  7.6720051765441895\n",
      "fps: 6.369385430745167\n",
      "TIMESTEP 103264 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.09092029 / Loss  0.1267881691455841\n",
      "fps: 6.097258322430585\n",
      "TIMESTEP 103265 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.094726905 / Loss  0.046044886112213135\n",
      "fps: 6.024385934925835\n",
      "TIMESTEP 103266 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.108064204 / Loss  0.24357560276985168\n",
      "fps: 5.780327638409795\n",
      "TIMESTEP 103267 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.046946555 / Loss  0.01943688467144966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 6.249922142402663\n",
      "TIMESTEP 103268 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.56184095 / Loss  7.81175422668457\n",
      "fps: 5.524752892579401\n",
      "TIMESTEP 103269 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.5862998 / Loss  0.2588821053504944\n",
      "fps: 5.319197181562467\n",
      "TIMESTEP 103270 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.03051728 / Loss  0.13875927031040192\n",
      "fps: 6.060572432607389\n",
      "TIMESTEP 103271 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.856661 / Loss  0.16479723155498505\n",
      "fps: 6.172814505209867\n",
      "TIMESTEP 103272 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.0169584 / Loss  0.0641898587346077\n",
      "fps: 5.7471334926446405\n",
      "TIMESTEP 103273 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.14680347 / Loss  0.018729764968156815\n",
      "fps: 5.102000997457699\n",
      "TIMESTEP 103274 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.127643 / Loss  0.22014304995536804\n",
      "fps: 6.84934173353844\n",
      "TIMESTEP 103275 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.012968145 / Loss  3.371068000793457\n",
      "fps: 3.5210981940778647\n",
      "TIMESTEP 103276 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  13.853926 / Loss  0.020753787830471992\n",
      "fps: 5.713968100004904\n",
      "TIMESTEP 103277 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.123479314 / Loss  0.14540687203407288\n",
      "fps: 4.902247343347499\n",
      "TIMESTEP 103278 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.26029223 / Loss  0.021023854613304138\n",
      "fps: 5.050506218150642\n",
      "TIMESTEP 103279 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.03344158 / Loss  0.19335250556468964\n",
      "fps: 5.987372327896934\n",
      "TIMESTEP 103280 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.13038415 / Loss  0.09305965900421143\n",
      "fps: 6.098198006961387\n",
      "TIMESTEP 103281 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.11136361 / Loss  0.018519343808293343\n",
      "fps: 5.464506731773921\n",
      "TIMESTEP 103282 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.012420252 / Loss  0.07331342995166779\n",
      "fps: 5.813971927509432\n",
      "TIMESTEP 103283 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.045702524 / Loss  0.055758193135261536\n",
      "fps: 5.814020282446092\n",
      "TIMESTEP 103284 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.17106757 / Loss  0.15501205623149872\n",
      "fps: 6.848748977415789\n",
      "TIMESTEP 103285 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.16383845 / Loss  0.08515800535678864\n",
      "fps: 5.435063858019572\n",
      "TIMESTEP 103286 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.4828205 / Loss  0.08291295915842056\n",
      "fps: 5.076743566777216\n",
      "TIMESTEP 103287 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.027020164 / Loss  0.12087763845920563\n",
      "fps: 3.6364128182497586\n",
      "TIMESTEP 103288 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.37973535 / Loss  0.06731817126274109\n",
      "fps: 4.608208696951485\n",
      "TIMESTEP 103289 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.26082453 / Loss  0.035231366753578186\n",
      "fps: 6.710725342591778\n",
      "TIMESTEP 103290 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.13068962 / Loss  0.13338898122310638\n",
      "fps: 6.370052897678\n",
      "TIMESTEP 103291 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  9.546672 / Loss  0.05093420669436455\n",
      "fps: 5.319028542369701\n",
      "TIMESTEP 103292 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.13713306 / Loss  0.033644672483205795\n",
      "fps: 5.952432245255358\n",
      "TIMESTEP 103293 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  17.349255 / Loss  0.03661620616912842\n",
      "fps: 7.09213698972949\n",
      "TIMESTEP 103294 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.41500863 / Loss  0.2510314881801605\n",
      "fps: 6.535922372458242\n",
      "TIMESTEP 103295 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.10753567 / Loss  0.10152880847454071\n",
      "fps: 7.0422318596759865\n",
      "TIMESTEP 103296 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.26677248 / Loss  0.03559520095586777\n",
      "fps: 7.19427244316525\n",
      "TIMESTEP 103297 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.63782823 / Loss  0.007795198354870081\n",
      "fps: 6.8964732538504165\n",
      "TIMESTEP 103298 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  17.171665 / Loss  0.0718085765838623\n",
      "fps: 5.102056853278448\n",
      "TIMESTEP 103299 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.42047855 / Loss  0.05561736971139908\n",
      "fps: 5.813955809375953\n",
      "TIMESTEP 103300 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.14758056 / Loss  0.11099673062562943\n",
      "fps: 5.987731322530311\n",
      "TIMESTEP 103301 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.006033793 / Loss  0.12593625485897064\n",
      "fps: 6.711799204691838\n",
      "TIMESTEP 103302 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.2510615 / Loss  0.1769392341375351\n",
      "fps: 6.944430371154059\n",
      "TIMESTEP 103303 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  14.4546 / Loss  0.07685105502605438\n",
      "fps: 6.944361385261604\n",
      "TIMESTEP 103304 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.39584363 / Loss  0.07256116718053818\n",
      "fps: 7.143058587909112\n",
      "TIMESTEP 103305 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5091165 / Loss  0.03307424485683441\n",
      "fps: 6.622348252799373\n",
      "TIMESTEP 103306 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.96625 / Loss  0.02168133854866028\n",
      "fps: 6.666641235448575\n",
      "TIMESTEP 103307 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.16436589 / Loss  0.030762173235416412\n",
      "fps: 7.142632841809132\n",
      "TIMESTEP 103308 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.0441285 / Loss  0.03321228176355362\n",
      "fps: 7.299227493504437\n",
      "TIMESTEP 103309 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.20755935 / Loss  0.22088778018951416\n",
      "fps: 7.142961270040225\n",
      "TIMESTEP 103310 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.36309928 / Loss  0.031370677053928375\n",
      "fps: 5.882309052685906\n",
      "TIMESTEP 103311 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6513223 / Loss  0.025200501084327698\n",
      "fps: 4.608269453255384\n",
      "TIMESTEP 103312 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.2824552 / Loss  0.188615083694458\n",
      "fps: 6.849554256001907\n",
      "TIMESTEP 103313 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.11147414 / Loss  0.04445968195796013\n",
      "fps: 6.849129224262515\n",
      "TIMESTEP 103314 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.012382068 / Loss  0.013675487600266933\n",
      "fps: 6.060616219137386\n",
      "TIMESTEP 103315 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  19.9475 / Loss  2.1272659301757812\n",
      "fps: 6.21124399504795\n",
      "TIMESTEP 103316 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.044861622 / Loss  0.035358961671590805\n",
      "fps: 6.62258874873092\n",
      "TIMESTEP 103317 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.32841712 / Loss  0.12501859664916992\n",
      "fps: 6.802805913503256\n",
      "TIMESTEP 103318 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.24825463 / Loss  0.025606492534279823\n",
      "fps: 7.19427244316525\n",
      "TIMESTEP 103319 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.4048417 / Loss  0.04161416366696358\n",
      "fps: 5.347633454838467\n",
      "TIMESTEP 103320 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.36938334 / Loss  0.12844085693359375\n",
      "fps: 5.524949384646391\n",
      "TIMESTEP 103321 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.010658219 / Loss  0.08464080095291138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 6.493414167435581\n",
      "TIMESTEP 103322 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.24011064 / Loss  0.05345343053340912\n",
      "fps: 6.849397659223889\n",
      "TIMESTEP 103323 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.2825684 / Loss  0.03600432723760605\n",
      "fps: 6.944188926526733\n",
      "TIMESTEP 103324 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.2974742 / Loss  0.035264838486909866\n",
      "fps: 7.091585397194682\n",
      "TIMESTEP 103325 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.07697604 / Loss  0.03078477643430233\n",
      "fps: 6.7573009487568205\n",
      "TIMESTEP 103326 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  18.611681 / Loss  0.14295122027397156\n",
      "fps: 6.097586292619315\n",
      "TIMESTEP 103327 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.18259428 / Loss  0.0185825377702713\n",
      "fps: 6.711358879665128\n",
      "TIMESTEP 103328 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.14261462 / Loss  0.02798352763056755\n",
      "fps: 7.042373749330486\n",
      "TIMESTEP 103329 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.4455703 / Loss  3.370917320251465\n",
      "fps: 6.289273622053147\n",
      "TIMESTEP 103330 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.60154104 / Loss  0.13769382238388062\n",
      "fps: 6.992977518723282\n",
      "TIMESTEP 103331 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.45188868 / Loss  0.057609640061855316\n",
      "fps: 6.801382880048777\n",
      "TIMESTEP 103332 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.22407871 / Loss  0.10598982870578766\n",
      "fps: 5.715252786903563\n",
      "TIMESTEP 103333 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.36551017 / Loss  0.0696483850479126\n",
      "fps: 4.5454736584292705\n",
      "TIMESTEP 103334 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.6657421 / Loss  0.049529485404491425\n",
      "fps: 6.711337401873406\n",
      "TIMESTEP 103335 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.15943938 / Loss  17.95270538330078\n",
      "fps: 5.8138107501961365\n",
      "TIMESTEP 103336 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.6720562 / Loss  0.036622099578380585\n",
      "fps: 5.586617597502321\n",
      "TIMESTEP 103337 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.26175588 / Loss  2.676919460296631\n",
      "fps: 5.464471135117952\n",
      "TIMESTEP 103338 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.70994365 / Loss  0.025406397879123688\n",
      "fps: 5.554979584214618\n",
      "TIMESTEP 103339 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5104243 / Loss  0.3333229124546051\n",
      "fps: 5.5871236391198185\n",
      "TIMESTEP 103340 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.13621506 / Loss  11.552218437194824\n",
      "fps: 4.926176136203479\n",
      "TIMESTEP 103341 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 1 / REWARD 0.1 / Q_MAX  0.47363424 / Loss  0.03810770437121391\n",
      "fps: 6.756636940048456\n",
      "TIMESTEP 103342 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.27457958 / Loss  0.057575199753046036\n",
      "fps: 6.711380357594319\n",
      "TIMESTEP 103343 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5933158 / Loss  0.0477069690823555\n",
      "fps: 4.9261472076031465\n",
      "TIMESTEP 103344 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.6855764 / Loss  0.1032201498746872\n",
      "fps: 5.586535746442404\n",
      "TIMESTEP 103345 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.118267074 / Loss  0.04662070423364639\n",
      "fps: 4.166732729528708\n",
      "TIMESTEP 103346 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5011701 / Loss  0.030044512823224068\n",
      "fps: 6.756506330745191\n",
      "TIMESTEP 103347 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6001048 / Loss  0.06800781190395355\n",
      "fps: 6.84946477125197\n",
      "TIMESTEP 103348 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.20185807 / Loss  0.021335501223802567\n",
      "fps: 6.578856641826512\n",
      "TIMESTEP 103349 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.16145709 / Loss  0.04816853255033493\n",
      "fps: 5.987739870546281\n",
      "TIMESTEP 103350 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.44118387 / Loss  0.04170894995331764\n",
      "fps: 6.849531884595223\n",
      "TIMESTEP 103351 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.4948978 / Loss  0.07106827944517136\n",
      "fps: 6.536227931700278\n",
      "TIMESTEP 103352 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.46461165 / Loss  0.05626961588859558\n",
      "fps: 7.352842489827903\n",
      "TIMESTEP 103353 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.20966992 / Loss  0.3410934805870056\n",
      "fps: 7.245800366237087\n",
      "TIMESTEP 103354 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.34160218 / Loss  3.3444371223449707\n",
      "fps: 6.8965639711069056\n",
      "TIMESTEP 103355 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.47405252 / Loss  0.08346053957939148\n",
      "fps: 6.451574399227221\n",
      "TIMESTEP 103356 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5931478 / Loss  0.08911416679620743\n",
      "fps: 5.917204640874001\n",
      "TIMESTEP 103357 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.19997278 / Loss  0.1129647046327591\n",
      "fps: 5.2909549393173725\n",
      "TIMESTEP 103358 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.8477073 / Loss  0.12401308119297028\n",
      "fps: 6.622756060551035\n",
      "TIMESTEP 103359 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.6784753 / Loss  0.21356835961341858\n",
      "fps: 6.711208538009824\n",
      "TIMESTEP 103360 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.20856208 / Loss  0.03773912414908409\n",
      "fps: 6.711434053018726\n",
      "TIMESTEP 103361 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.109443754 / Loss  0.24271613359451294\n",
      "fps: 5.6180310456093725\n",
      "TIMESTEP 103362 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.8670021 / Loss  10.08162784576416\n",
      "fps: 5.263110079367569\n",
      "TIMESTEP 103363 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7749285 / Loss  0.10728448629379272\n",
      "fps: 6.802011588853554\n",
      "TIMESTEP 103364 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.7654184 / Loss  0.10247519612312317\n",
      "fps: 6.850158339226481\n",
      "TIMESTEP 103365 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.44631004 / Loss  0.03698821738362312\n",
      "fps: 7.0438047895744464\n",
      "TIMESTEP 103366 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.5379923 / Loss  0.17940542101860046\n",
      "fps: 6.369501501902815\n",
      "TIMESTEP 103367 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.27531895 / Loss  0.03833547979593277\n",
      "fps: 7.042208211956111\n",
      "TIMESTEP 103368 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.31836388 / Loss  0.31733208894729614\n",
      "fps: 5.290908219361252\n",
      "TIMESTEP 103369 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.0037823692 / Loss  0.2801961898803711\n",
      "fps: 5.495882972645747\n",
      "TIMESTEP 103370 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.4394685 / Loss  0.053559545427560806\n",
      "fps: 6.8967227320486915\n",
      "TIMESTEP 103371 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.05308596 / Loss  0.14468848705291748\n",
      "fps: 6.896575310931776\n",
      "TIMESTEP 103372 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  1.2570213 / Loss  0.02689215913414955\n",
      "fps: 7.092005079360785\n",
      "TIMESTEP 103373 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.688231 / Loss  0.032649196684360504\n",
      "fps: 6.451564475590735\n",
      "TIMESTEP 103374 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.42387837 / Loss  0.07950681447982788\n",
      "fps: 7.043296171471848\n",
      "TIMESTEP 103375 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.040781915 / Loss  0.06078752502799034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 5.848010161470904\n",
      "TIMESTEP 103376 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.61330414 / Loss  0.13669797778129578\n",
      "fps: 5.649746493747205\n",
      "TIMESTEP 103377 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.35264367 / Loss  0.1011316105723381\n",
      "fps: 6.993024155362598\n",
      "TIMESTEP 103378 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.4730799 / Loss  0.2233622819185257\n",
      "fps: 6.535881633384497\n",
      "TIMESTEP 103379 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.15865028 / Loss  0.029476560652256012\n",
      "fps: 4.608335274392521\n",
      "TIMESTEP 103380 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8637547 / Loss  0.07561469078063965\n",
      "fps: 6.172887182989144\n",
      "TIMESTEP 103381 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.1629718 / Loss  0.49917516112327576\n",
      "fps: 6.622557378705774\n",
      "TIMESTEP 103382 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.2851006 / Loss  0.16150742769241333\n",
      "fps: 6.849386474013737\n",
      "TIMESTEP 103383 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.09204359 / Loss  0.22266076505184174\n",
      "fps: 6.368708433295879\n",
      "TIMESTEP 103384 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.055629 / Loss  0.029684165492653847\n",
      "fps: 7.143812891314271\n",
      "TIMESTEP 103385 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.3036813 / Loss  0.021039344370365143\n",
      "fps: 6.8026293808823315\n",
      "TIMESTEP 103386 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.27842426 / Loss  0.10914911329746246\n",
      "fps: 7.246488886585292\n",
      "TIMESTEP 103387 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.62971807 / Loss  0.04083496332168579\n",
      "fps: 6.493384009226935\n",
      "TIMESTEP 103388 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.22832775 / Loss  0.06430923193693161\n",
      "fps: 4.716808456802272\n",
      "TIMESTEP 103389 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.014204986 / Loss  0.025928866118192673\n",
      "fps: 5.952584304425512\n",
      "TIMESTEP 103390 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.5156214 / Loss  0.05570351704955101\n",
      "fps: 7.245474929433429\n",
      "TIMESTEP 103391 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  11.565571 / Loss  0.11823854595422745\n",
      "fps: 6.4934644317391905\n",
      "TIMESTEP 103392 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  18.023123 / Loss  0.030945252627134323\n",
      "fps: 5.1541196175365\n",
      "TIMESTEP 103393 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.4971643 / Loss  0.12141873687505722\n",
      "fps: 6.5359020028578865\n",
      "TIMESTEP 103394 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.48964673 / Loss  2.782421588897705\n",
      "fps: 6.756691362081825\n",
      "TIMESTEP 103395 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9519513 / Loss  0.03192692622542381\n",
      "fps: 7.042385573726452\n",
      "TIMESTEP 103396 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.016578399 / Loss  2.690232276916504\n",
      "fps: 7.518816293531669\n",
      "TIMESTEP 103397 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.5182401 / Loss  0.06061485409736633\n",
      "fps: 7.194112027223813\n",
      "TIMESTEP 103398 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.26576063 / Loss  7.434935092926025\n",
      "fps: 5.376630402038716\n",
      "TIMESTEP 103399 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.833983 / Loss  0.13426527380943298\n",
      "fps: 6.368176607681037\n",
      "TIMESTEP 103400 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.55605 / Loss  0.01847057044506073\n",
      "fps: 6.535932557306032\n",
      "TIMESTEP 103401 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.02247306 / Loss  0.11132519692182541\n",
      "fps: 6.756756669679118\n",
      "TIMESTEP 103402 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.052306168 / Loss  0.1121266633272171\n",
      "fps: 7.352958501044837\n",
      "TIMESTEP 103403 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8199893 / Loss  0.08146637678146362\n",
      "fps: 7.091453507343704\n",
      "TIMESTEP 103404 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6709019 / Loss  0.030148940160870552\n",
      "fps: 7.0929045655784\n",
      "TIMESTEP 103405 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.40875906 / Loss  7.6082305908203125\n",
      "fps: 6.13510888517032\n",
      "TIMESTEP 103406 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.720998 / Loss  0.09272505342960358\n",
      "fps: 5.494018450914359\n",
      "TIMESTEP 103407 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.073904 / Loss  0.09532010555267334\n",
      "fps: 6.024628228091923\n",
      "TIMESTEP 103408 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.040065482 / Loss  0.047406695783138275\n",
      "fps: 6.62253646552078\n",
      "TIMESTEP 103409 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.57734877 / Loss  0.03509245812892914\n",
      "fps: 7.462683061791306\n",
      "TIMESTEP 103410 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  16.706768 / Loss  0.14633263647556305\n",
      "fps: 6.451554551984779\n",
      "TIMESTEP 103411 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  15.748899 / Loss  4.567728519439697\n",
      "fps: 5.434901876939623\n",
      "TIMESTEP 103412 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.4070674 / Loss  0.08025558292865753\n",
      "fps: 6.41026056416597\n",
      "TIMESTEP 103413 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.002981633 / Loss  0.10962533950805664\n",
      "fps: 6.578485175954666\n",
      "TIMESTEP 103414 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.6672713 / Loss  1.2790884971618652\n",
      "fps: 4.5456559294076335\n",
      "TIMESTEP 103415 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.12691677 / Loss  0.15323011577129364\n",
      "fps: 7.042480170323655\n",
      "TIMESTEP 103416 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.136563 / Loss  0.10203573107719421\n",
      "fps: 7.246238500410314\n",
      "TIMESTEP 103417 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.2700047 / Loss  0.11539077013731003\n",
      "fps: 6.24999664724053\n",
      "TIMESTEP 103418 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.47667196 / Loss  0.03685622662305832\n",
      "fps: 7.246301095331882\n",
      "TIMESTEP 103419 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  1.204842 / Loss  0.08165279030799866\n",
      "fps: 6.993047473915523\n",
      "TIMESTEP 103420 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.22882004 / Loss  0.023597832769155502\n",
      "fps: 5.847944932357538\n",
      "TIMESTEP 103421 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.616365 / Loss  4.0850067138671875\n",
      "fps: 5.154651692960367\n",
      "TIMESTEP 103422 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.3418283 / Loss  0.030522150918841362\n",
      "fps: 5.780471031520165\n",
      "TIMESTEP 103423 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.98696566 / Loss  0.2612364888191223\n",
      "fps: 6.060554918172544\n",
      "TIMESTEP 103424 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.542308 / Loss  0.03129177168011665\n",
      "fps: 7.2993545220870395\n",
      "TIMESTEP 103425 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  1.533614 / Loss  0.14053228497505188\n",
      "fps: 5.952406902815622\n",
      "TIMESTEP 103426 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.67231303 / Loss  0.12279047071933746\n",
      "fps: 6.135117859154105\n",
      "TIMESTEP 103427 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.1140807 / Loss  0.031219590455293655\n",
      "fps: 6.023987924172767\n",
      "TIMESTEP 103428 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.031337135 / Loss  0.1430397629737854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 6.369279035900146\n",
      "TIMESTEP 103429 / STATE train / EPSILON 9.999999987391849e-05 / ACTION 0 / REWARD 0.1 / Q_MAX  0.23141809 / Loss  0.04241332411766052\n",
      "fps: 7.299291007243073\n"
     ]
    }
   ],
   "source": [
    "playGame(observe=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
